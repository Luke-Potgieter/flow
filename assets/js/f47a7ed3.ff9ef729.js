"use strict";(self.webpackChunksite=self.webpackChunksite||[]).push([[5527],{3905:function(e,t,a){a.d(t,{Zo:function(){return c},kt:function(){return h}});var n=a(7294);function o(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function i(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function r(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?i(Object(a),!0).forEach((function(t){o(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):i(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function s(e,t){if(null==e)return{};var a,n,o=function(e,t){if(null==e)return{};var a,n,o={},i=Object.keys(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||(o[a]=e[a]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(o[a]=e[a])}return o}var l=n.createContext({}),u=function(e){var t=n.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):r(r({},t),e)),a},c=function(e){var t=u(e.components);return n.createElement(l.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},p=n.forwardRef((function(e,t){var a=e.components,o=e.mdxType,i=e.originalType,l=e.parentName,c=s(e,["components","mdxType","originalType","parentName"]),p=u(a),h=o,m=p["".concat(l,".").concat(h)]||p[h]||d[h]||i;return a?n.createElement(m,r(r({ref:t},c),{},{components:a})):n.createElement(m,r({ref:t},c))}));function h(e,t){var a=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var i=a.length,r=new Array(i);r[0]=p;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:o,r[1]=s;for(var u=2;u<i;u++)r[u]=a[u];return n.createElement.apply(null,r)}return n.createElement.apply(null,a)}p.displayName="MDXCreateElement"},293:function(e,t,a){a.r(t),a.d(t,{frontMatter:function(){return s},contentTitle:function(){return l},metadata:function(){return u},toc:function(){return c},default:function(){return p}});var n=a(7462),o=a(3366),i=(a(7294),a(3905)),r=["components"],s={sidebar_position:2,description:"Common pain points you might have, and how Flow addresses them."},l="Who should use Flow?",u={unversionedId:"overview/who-should-use-flow",id:"overview/who-should-use-flow",title:"Who should use Flow?",description:"Common pain points you might have, and how Flow addresses them.",source:"@site/docs/overview/who-should-use-flow.md",sourceDirName:"overview",slug:"/overview/who-should-use-flow",permalink:"/overview/who-should-use-flow",editUrl:"https://github.com/estuary/flow/edit/master/site/docs/overview/who-should-use-flow.md",tags:[],version:"current",sidebarPosition:2,frontMatter:{sidebar_position:2,description:"Common pain points you might have, and how Flow addresses them."},sidebar:"tutorialSidebar",previous:{title:"Flow documentation",permalink:"/"},next:{title:"Comparisons",permalink:"/overview/comparisons"}},c=[{value:"Benefits",id:"benefits",children:[{value:"Fully integrated pipelines",id:"fully-integrated-pipelines",children:[],level:3},{value:"Efficient architecture",id:"efficient-architecture",children:[],level:3},{value:"Powerful transformations",id:"powerful-transformations",children:[],level:3},{value:"Data integrity",id:"data-integrity",children:[],level:3},{value:"Dynamic scaling",id:"dynamic-scaling",children:[],level:3}],level:2}],d={toc:c};function p(e){var t=e.components,a=(0,o.Z)(e,r);return(0,i.kt)("wrapper",(0,n.Z)({},d,a,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"who-should-use-flow"},"Who should use Flow?"),(0,i.kt)("p",null,"Flow is a DataOps platform designed for all members of your data team. Its powerful CLI gives backend engineers data integration superpowers. At the same time, Flow allows data analysts and other user cohorts to meaningfully contribute and participate."),(0,i.kt)("p",null,'If you answer "yes" to any of the following questions, Flow can help:'),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Do you work with multiple databases and struggle to keep them in sync with one another?"),(0,i.kt)("li",{parentName:"ul"},"Do you issue repeated OLAP queries to your warehouse that are expensive to execute?",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Or do you need instant metrics for specific events like Black Friday?"))),(0,i.kt)("li",{parentName:"ul"},"Do you operate separate batch and streaming systems, and grapple with reconciling them?"),(0,i.kt)("li",{parentName:"ul"},"Do you manage continuous processing workflows with tools like Spark,\nFlink, or Google Cloud Dataflow, and want a faster, easier-to-evolve alternative?"),(0,i.kt)("li",{parentName:"ul"},"Is your organization held back by a data engineering bottleneck,\nwhile less-technical stakeholders are blocked from contributing by a high barrier to entry?"),(0,i.kt)("li",{parentName:"ul"},"Do you have a ",(0,i.kt)("a",{parentName:"li",href:"https://martinfowler.com/articles/data-monolith-to-mesh.html"},"distributed data mesh"),"\nand are seeking a tool to help with orchestration?")),(0,i.kt)("h2",{id:"benefits"},"Benefits"),(0,i.kt)("p",null,"These characteristics set Flow apart from other data integration workflows and address the pain points listed above."),(0,i.kt)("h3",{id:"fully-integrated-pipelines"},"Fully integrated pipelines"),(0,i.kt)("p",null,"With Flow, you can build, test, and evolve pipelines that continuously capture, transform, and materialize data across all of your systems. With one tool, you can power workflows that have historically required you to first piece together services, then integrate and operate them in-house to meet your needs."),(0,i.kt)("p",null,"To achieve comparable capabilities to Flow you would need:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"A low-latency streaming system, such as AWS Kenesis"),(0,i.kt)("li",{parentName:"ul"},"Data lake build-out, such as Kenesis Firehose to S3"),(0,i.kt)("li",{parentName:"ul"},"Custom ETL application development, such as Spark, Flink, or AWS \u03bb"),(0,i.kt)("li",{parentName:"ul"},"Supplemental data stores for intermediate transformation states"),(0,i.kt)("li",{parentName:"ul"},"ETL job management and execution, such as a self-hosting or Google Cloud Dataflow"),(0,i.kt)("li",{parentName:"ul"},'Custom reconciliation of historical vs streaming datasets, including onerous "backfills" of new streaming applications from historical data')),(0,i.kt)("p",null,"Flow's declarative GitOps workflow is a dramatic simplification from this inherent complexity. It saves you time and costs, catches mistakes before they hit production, and keeps your data fresh across all the places you use it."),(0,i.kt)("h3",{id:"efficient-architecture"},"Efficient architecture"),(0,i.kt)("p",null,"Flow mixes a variety of architectural techniques to deliver great throughput, avoid latency, and minimize operating costs. These include:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Leveraging reductions to reduce the amount of data that must be ingested, stored, and processed, often dramatically"),(0,i.kt)("li",{parentName:"ul"},"Executing transformations predominantly in-memory"),(0,i.kt)("li",{parentName:"ul"},"Optimistic pipelining and vectorization of internal remote procedure calls (RPCs) and operations"),(0,i.kt)("li",{parentName:"ul"},"A cloud-native design that optimizes for public cloud pricing models")),(0,i.kt)("p",null,"Flow also makes it easy to ",(0,i.kt)("strong",{parentName:"p"},"materialize")," focused data rollups as views directly into your warehouse, so you don't need to repeatedly query the much larger source datasets. This can dramatically lower warehouse costs."),(0,i.kt)("h3",{id:"powerful-transformations"},"Powerful transformations"),(0,i.kt)("p",null,"With Flow, you can build pipelines that join a current event with an event that happened days, weeks, even years in the past. Flow can model arbitrary stream-to-stream joins without the windowing constraints imposed by other systems, which limit how far back in time you can join."),(0,i.kt)("p",null,"Flow transforms data in durable micro-transactions, meaning that an outcome, once committed, won't be silently re-ordered or changed due to a crash or machine failure. This makes Flow uniquely suited for operational workflows, like assigning a dynamic amount of available inventory to a stream of requests \u2014 decisions that, once made, should not be forgotten. You can also evolve transformations as business requirements change, enriching them with new datasets or behaviors without needing to re-compute from scratch."),(0,i.kt)("h3",{id:"data-integrity"},"Data integrity"),(0,i.kt)("p",null,"Flow supports strong schematization, durable transactions with exactly-once semantics, and easy end-to-end testing to ensure that your data is accurate and that changes don't break pipelines."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"JSON schemas are verified with every document read or written. If a document violates its schema, Flow pauses the pipeline, giving you a chance to fix the error."),(0,i.kt)("li",{parentName:"ul"},"Schemas can encode constraints, like that a latitude value must be between +90 and -90 degrees, or that a field must be a valid email address."),(0,i.kt)("li",{parentName:"ul"},"Flow projects JSON schema into other flavors, like TypeScript types or SQL tables. Strong type checking catches bugs before they're applied to production."),(0,i.kt)("li",{parentName:"ul"},"Flow's declarative tests verify the integrated, end-to-end behavior of processing pipelines.")),(0,i.kt)("h3",{id:"dynamic-scaling"},"Dynamic scaling"),(0,i.kt)("p",null,"The Flow runtime scales from a single process for local development up to a large Kubernetes cluster for high-volume production deployments. Processing tasks are quickly reassigned upon any machine failure for high availability."),(0,i.kt)("p",null,"Each process can also be scaled independently, at any time, and without downtime. This is unique to Flow. Comparable systems require that an arbitrary data partitioning be decided upfront, a crucial performance knob that's awkward and expensive to change. Instead, Flow can repeatedly split a running task into two new tasks, each half the size, without stopping it or impacting its downstream uses."))}p.isMDXComponent=!0}}]);